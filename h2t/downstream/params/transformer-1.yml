metadata:
  option_name: ""
  architecture_name: "transformer-1"

loader_kwargs:
  train: { 'batch_size' : 8, 'nr_procs' : 4}
  infer: { 'batch_size' : 8, 'nr_procs' : 4}

model_kwargs:
  embed_dim: 2048
  num_types: 2

  layers:
    # last one is the pooling using hopfield
    - state_dim: 128
      num_states: 16
      num_heads: 8
      drop_out: 0.5

optimizer_kwargs:
  betas:
  - 0.9
  - 0.999
  lr: 1.0e-04
  weight_decay: 0.0
seed: 5
